{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import itertools\n",
    "from random import choice\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"D:\\\\graphs\\\\outputacm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"outputacm.txt\"\n",
    "if os.path.exists(\"D:\\\\graphs\\\\outputacm.txt\"):\n",
    "    path = \"D:\\\\graphs\\\\outputacm.txt\"\n",
    "\n",
    "test = open(path, 'r',  encoding=\"utf8\") \n",
    "test.readlines()[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for parsing citation data\n",
    "\n",
    "works for aminer citation sets V1-V10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(graph, reference):\n",
    "    graph.add_node(reference['index']) # add node\n",
    "    graph.add_node(reference['index'], title=reference['title']) # add title attribute to node\n",
    "    graph.add_node(reference['index'], journal=reference['journal']) # add journal attribute to node\n",
    "    if 'abstract' in reference:\n",
    "        graph.add_node(reference['index'], abstract=reference['abstract']) # add abstract attribute to node\n",
    "    else:\n",
    "        graph.add_node(reference['index'], abstract=\"\")\n",
    "    for citation in reference['citations']:\n",
    "        graph.add_edge(reference['index'], citation) # add edge to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(graph):\n",
    "    with open(path, 'r',  encoding=\"utf8\") as f:\n",
    "        reference={}\n",
    "        citations=[]\n",
    "        readFile = f.readlines()\n",
    "        for line in readFile:\n",
    "            \n",
    "            if '#*' in line: # article title\n",
    "                if (bool(reference)):\n",
    "                    reference['citations'] = citations\n",
    "                    citations=[]\n",
    "                    create_graph(graph, reference)\n",
    "                    try:\n",
    "                        yield reference\n",
    "                    except IndexError as e:\n",
    "                        continue\n",
    "                    reference={}\n",
    "                reference['title'] = line[2:].rstrip()\n",
    "            elif '#@' in line: # authors\n",
    "                reference['author'] = line[2:].rstrip().rsplit(\";\")\n",
    "            elif '#t' in line: # year published\n",
    "                reference['year'] = line[2:].rstrip()\n",
    "            elif '#c' in line: # journal\n",
    "                reference['journal'] = line[2:].rstrip()\n",
    "            elif '#index' in line: # index\n",
    "                reference['index'] = line[6:].rstrip()\n",
    "            elif '#%' in line: # id of cited paper\n",
    "                citations.append(line[2:].rstrip())\n",
    "            elif '#!' in line: # abstract\n",
    "                reference['abstract'] = line[2:].rstrip()\n",
    "                if (bool(reference)):\n",
    "                    reference['citations'] = citations\n",
    "                    citations=[]\n",
    "                    create_graph(graph, reference)\n",
    "        yield reference\n",
    "        create_graph(graph, reference)\n",
    "        return reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NetworkX Graph G and pandas dataframe data from parsed citation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(parse_data(G), columns =('index', 'title', 'author',\n",
    "                                            'year', 'journal', 'citations', 'abstract'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629814 nodes\n",
      "632751 edges\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_nodes(), 'nodes')\n",
    "print(G.size(), 'edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structure preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Automated Deduction in Geometry: 5th Internati...</td>\n",
       "      <td>[Hoon Hong,Dongming Wang]</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A+ Certification Core Hardware (Text &amp; Lab Man...</td>\n",
       "      <td>[Charles J. Brooks]</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Performance engineering in industry: current p...</td>\n",
       "      <td>[Ahmed E. Hassan,Parminder Flora]</td>\n",
       "      <td>2007</td>\n",
       "      <td>Proceedings of the 6th international workshop ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>This panel session discusses performance engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Dude, You Can Do It! How to Build a Sweeet PC</td>\n",
       "      <td>[Darrel Creacy,Carlito Vicencio]</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>Whether you're frustrated with current PC offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>What Every Programmer Needs to Know about Secu...</td>\n",
       "      <td>[Neil Daswani,Anita Kesavan]</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629809</td>\n",
       "      <td>629809</td>\n",
       "      <td>Mining A</td>\n",
       "      <td>[]</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the VLDB Endowment</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629810</td>\n",
       "      <td>629810</td>\n",
       "      <td>Review article</td>\n",
       "      <td>[]</td>\n",
       "      <td>2008</td>\n",
       "      <td>Communications of the ACM</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629811</td>\n",
       "      <td>629811</td>\n",
       "      <td>Multimodal system evaluation using modality ef...</td>\n",
       "      <td>[Manolis Perakakis,Alexandros Potamianos]</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the 10th international conferen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In this paper, we propose two new objective me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629812</td>\n",
       "      <td>629812</td>\n",
       "      <td>Computer System Architecture</td>\n",
       "      <td>[V. K. Jain]</td>\n",
       "      <td>2007</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629813</td>\n",
       "      <td>629813</td>\n",
       "      <td>Oppositional target domain estimation using gr...</td>\n",
       "      <td>[Maryam Shokri,Hamid R. Tizhoosh,Mohamed S. Ka...</td>\n",
       "      <td>2009</td>\n",
       "      <td>Applied Soft Computing</td>\n",
       "      <td>[]</td>\n",
       "      <td>In this paper we address the problem of estima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629814 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                              title  \\\n",
       "0            0  Automated Deduction in Geometry: 5th Internati...   \n",
       "1            1  A+ Certification Core Hardware (Text & Lab Man...   \n",
       "2            2  Performance engineering in industry: current p...   \n",
       "3            3      Dude, You Can Do It! How to Build a Sweeet PC   \n",
       "4            4  What Every Programmer Needs to Know about Secu...   \n",
       "...        ...                                                ...   \n",
       "629809  629809                                           Mining A   \n",
       "629810  629810                                     Review article   \n",
       "629811  629811  Multimodal system evaluation using modality ef...   \n",
       "629812  629812                       Computer System Architecture   \n",
       "629813  629813  Oppositional target domain estimation using gr...   \n",
       "\n",
       "                                                   author  year  \\\n",
       "0                               [Hoon Hong,Dongming Wang]  2006   \n",
       "1                                     [Charles J. Brooks]  2003   \n",
       "2                       [Ahmed E. Hassan,Parminder Flora]  2007   \n",
       "3                        [Darrel Creacy,Carlito Vicencio]  2005   \n",
       "4                            [Neil Daswani,Anita Kesavan]  2006   \n",
       "...                                                   ...   ...   \n",
       "629809                                                 []  2008   \n",
       "629810                                                 []  2008   \n",
       "629811          [Manolis Perakakis,Alexandros Potamianos]  2008   \n",
       "629812                                       [V. K. Jain]  2007   \n",
       "629813  [Maryam Shokri,Hamid R. Tizhoosh,Mohamed S. Ka...  2009   \n",
       "\n",
       "                                                  journal citations  \\\n",
       "0                                                                []   \n",
       "1                                                                []   \n",
       "2       Proceedings of the 6th international workshop ...        []   \n",
       "3                                                                []   \n",
       "4                                                                []   \n",
       "...                                                   ...       ...   \n",
       "629809                  Proceedings of the VLDB Endowment        []   \n",
       "629810                          Communications of the ACM        []   \n",
       "629811  Proceedings of the 10th international conferen...        []   \n",
       "629812                                                           []   \n",
       "629813                             Applied Soft Computing        []   \n",
       "\n",
       "                                                 abstract  \n",
       "0                                                     NaN  \n",
       "1                                                     NaN  \n",
       "2       This panel session discusses performance engin...  \n",
       "3       Whether you're frustrated with current PC offe...  \n",
       "4                                                     NaN  \n",
       "...                                                   ...  \n",
       "629809                                                NaN  \n",
       "629810                                                NaN  \n",
       "629811  In this paper, we propose two new objective me...  \n",
       "629812                                                NaN  \n",
       "629813  In this paper we address the problem of estima...  \n",
       "\n",
       "[629814 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing nodes without edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing isolated nodes, the network contains:\n",
      "217335 nodes\n",
      "Obviously edges are the same.\n",
      "632751 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"After removing isolated nodes, the network contains:\")\n",
    "print(G.number_of_nodes(), 'nodes')\n",
    "print(\"Obviously edges are the same.\")\n",
    "print(G.size(), 'edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for examining shared phrases using TextBlob NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordlist is the wordlist of the central node and comparison is wordlist of one of it's neighbor\n",
    "def shared_noun_phrases(wordlist, comparison):\n",
    "    count=0\n",
    "    for word in wordlist:\n",
    "        if word in comparison:\n",
    "            count+=1\n",
    "    if (len(wordlist) == 0):\n",
    "        return 0\n",
    "    return count/len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_noun_phrases(graph, starting_node):\n",
    "    noun_phrases= TextBlob(G.nodes[starting_node]['abstract']).noun_phrases\n",
    "    data_set=[]\n",
    "    index=str(starting_node)\n",
    "    for neighbor in graph.predecessors(index):\n",
    "        if 'abstract' in G.nodes[neighbor].keys():\n",
    "            data_set.append(shared_noun_phrases(noun_phrases, TextBlob(G.nodes[neighbor]['abstract']).noun_phrases))\n",
    "    return noun_phrases, data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the output of the TextBlob noun phrase extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new objective metrics', 'relative modality efficiency', 'multimodal synergy', 'valuable information', 'identify usability problems', 'multimodal systems', 'relative', 'modality efficiency', 'modality usage', 'identify suboptimal use', 'poor interface design', 'information asymmetries', 'multimodal', 'synergy measures', 'multiple input modalities', 'modality fusion', 'multimodal system', 'multimodal systems', 'mouse/keyboard modalities', 'multimodal interface usability issues', 'multimodal systems', 'maximize modalities synergy', 'intelligent multimodal interfaces']\n"
     ]
    }
   ],
   "source": [
    "print(find_noun_phrases(G, '629811')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for removing nodes without abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_only_nodes_with_abstract(graph):\n",
    "    no_abstracts = graph.copy()\n",
    "    for node in [x for x, y in graph.nodes(data=True) if y['abstract']=='']:\n",
    "        no_abstracts.remove_node(node)\n",
    "    #print(no_abstracts.number_of_nodes(), 'nodes after removing abstractless nodes')\n",
    "    return no_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting  nodes from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_nodes_with_average_degrees(graph, n):\n",
    "    G_no_isolated = graph.copy()\n",
    "    G_no_isolated.remove_nodes_from(list(nx.isolates(G_no_isolated)))\n",
    "    #print(G.number_of_nodes(), 'nodes in G,', G_no_isolated.number_of_nodes(), 'nodes in G_no_isolated')\n",
    "    node_list = [seq[0] for seq in sorted(G_no_isolated.degree, key=lambda x: x[1], reverse=True) ]\n",
    "    halfway_point = int(len(node_list)/7)\n",
    "    return node_list[halfway_point:(halfway_point+n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_nodes_with_highest_degrees(graph, n):\n",
    "    node_list = [ seq[0] for seq in sorted(graph.degree, key=lambda x: x[1], reverse=True)[0:n] ]\n",
    "    return node_list[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a selection of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected nodes have 10  edges (or more).\n"
     ]
    }
   ],
   "source": [
    "node_count = 20\n",
    "average_degree_nodes = select_n_nodes_with_average_degrees(G, node_count)\n",
    "print(\"Selected nodes have\", G.degree(average_degree_nodes[node_count-1]), \" edges (or more).\")\n",
    "#for node in average_degree_nodes:\n",
    "#    print(G.degree(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_degree_nodes = select_n_nodes_with_highest_degrees(graph_only_nodes_with_abstract(G), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate abstract similarity to neighbours percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_similarity_percentage(list):\n",
    "    if len(list) != 0:\n",
    "        return sum(list)/len(list)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing similarity method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 326368 // Similarity to neighbouring article abstracts: 0.004140127388535034\n",
      "Node: 151297 // Similarity to neighbouring article abstracts: 0.012987012987012995\n",
      "Node: 319217 // Similarity to neighbouring article abstracts: 0.00449438202247191\n",
      "Node: 207703 // Similarity to neighbouring article abstracts: 0.010070869078701973\n",
      "Node: 250081 // Similarity to neighbouring article abstracts: 0.03126897389192466\n"
     ]
    }
   ],
   "source": [
    "for node_index in highest_degree_nodes:\n",
    "    #print(find_noun_phrases(G, node_index)[0])  # uncomment me to see noun phrases\n",
    "    print(\"Node:\", node_index, \"// Similarity to neighbouring article abstracts:\", abstract_similarity_percentage(find_noun_phrases(graph_only_nodes_with_abstract(G), node_index)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity comparison methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comparison(graph, starting_node):\n",
    "    noun_phrases= TextBlob(graph.nodes[starting_node]['abstract']).noun_phrases\n",
    "    #data_set=[noun_phrases]\n",
    "    data_set=[]\n",
    "    random_node=take_random_node(graph, starting_node)\n",
    "    for neighbor in graph.predecessors(random_node):\n",
    "        if 'abstract' in graph.nodes[neighbor].keys():\n",
    "            data_set.append(shared_noun_phrases(noun_phrases, TextBlob(graph.nodes[neighbor]['abstract']).noun_phrases))\n",
    "    return random_node, noun_phrases, data_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_random_node(graph, starting):\n",
    "    while(True):\n",
    "        random_node=choice(list(graph.nodes()))\n",
    "        if random_node not in graph.neighbors(starting) and graph.in_degree[random_node]>10:\n",
    "            return random_node\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_similarities(graph, nodes):\n",
    "    data=[]\n",
    "    for node in nodes:\n",
    "        data.append(abstract_similarity_percentage(find_noun_phrases(graph_only_nodes_with_abstract(graph), node)[1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_similarities_random(graph, nodes):\n",
    "    data=[]\n",
    "    for node in nodes:\n",
    "        data.append(abstract_similarity_percentage(make_comparison(graph_only_nodes_with_abstract(graph), node)[2]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting nodes/articles to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = make_comparison(graph_only_nodes_with_abstract(G), '629813')\n",
    "#print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "The node 460163 is not in the digraph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programming\\Anaconda\\lib\\site-packages\\networkx\\classes\\digraph.py\u001b[0m in \u001b[0;36mpredecessors\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '460163'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-928ded612d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataMedian\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_total_similarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_degree_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataHigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_total_similarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_degree_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataHighRandom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_total_similarities_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_degree_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataMedianRandom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_total_similarities_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_degree_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-a89700a4b3be>\u001b[0m in \u001b[0;36mcalculate_total_similarities\u001b[1;34m(graph, nodes)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabstract_similarity_percentage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_only_nodes_with_abstract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-c66287e321c0>\u001b[0m in \u001b[0;36mfind_noun_phrases\u001b[1;34m(graph, starting_node)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstarting_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'abstract'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mdata_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshared_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_phrases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_phrases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\lib\\site-packages\\networkx\\classes\\digraph.py\u001b[0m in \u001b[0;36mpredecessors\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The node %s is not in the digraph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNetworkXError\u001b[0m: The node 460163 is not in the digraph."
     ]
    }
   ],
   "source": [
    "dataMedian=calculate_total_similarities(G, average_degree_nodes)\n",
    "dataHigh=calculate_total_similarities(G, highest_degree_nodes)\n",
    "\n",
    "dataHighRandom=calculate_total_similarities_random(G, highest_degree_nodes)\n",
    "dataMedianRandom=calculate_total_similarities_random(G, average_degree_nodes)\n",
    "\n",
    "print(dataHigh)\n",
    "print(dataHighRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataHigh)\n",
    "print(len(dataHighRandom))\n",
    "for thing in dataHighRandom:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgraph(G, starting_node):\n",
    "    \"\"\"Graph: a bigger graph to get the subgraph of\n",
    "       starting node: the central node to extract predecessors of\n",
    "       returns a subgraph of the central node and its predecessors\n",
    "    \"\"\"\n",
    "    nodes_list = [starting_node]\n",
    "    for n in list(G.predecessors(starting_node)):\n",
    "        nodes_list.append(n)\n",
    "    subgraph = G.subgraph(nodes_list).copy()\n",
    "    return subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network(graph, data, size_of_nodes, to_file):\n",
    "    \"\"\"Graph: the subgraph to be plotted\n",
    "       Data: a list of values between 0 and 1, denoting the percentage of shared noun phrases\n",
    "       with the central node\n",
    "    \"\"\"\n",
    "    blue_map = cm.get_cmap('twilight', len(graph))\n",
    "    color_list = [blue_map(d) for d in data]\n",
    "    if not to_file:\n",
    "        nx.draw_spring(subgraph, node_color=color_list, node_size=size_of_nodes)\n",
    "    else:\n",
    "        nx.draw_spring(subgraph, node_color=color_list, node_size=size_of_nodes)\n",
    "        plt.savefig(\"Graph.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the number of a node to draw a subgraph of\n",
    "node_number = '151297'\n",
    "subgraph = get_subgraph(G, node_number)\n",
    "_, data = find_noun_phrases(subgraph, node_number)\n",
    "\n",
    "# add color of the 1st node (add 0 as the 1st element of the list)\n",
    "data.insert(0, 1)\n",
    "\n",
    "# size_of_nodes: change according to the size of the graph\n",
    "# to_file: set to true to draw the plot to a file\n",
    "size_of_nodes = 100\n",
    "to_file = True\n",
    "draw_network(subgraph, data, size_of_nodes, to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ongelma: värit plotataan välillä 0  ja 1, mutta kaikki arvot on joko 0 tai suhteellisen lähellä nollaa - kunnon kontrastia ei tule. Arvot pitää ehkä normalisoida jotenkin?\n",
    "\n",
    "Erilaisia color mappeja (tässä käytetty 'twilight'): https://matplotlib.org/3.1.1/tutorials/colors/colormaps.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
