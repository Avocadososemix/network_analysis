{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['629814\\n',\n",
       " '#*Automated Deduction in Geometry: 5th International Workshop, ADG 2004, Gainesville, FL, USA, September 16-18, 2004, Revised Papers (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)\\n',\n",
       " '#@Hoon Hong,Dongming Wang\\n',\n",
       " '#t2006\\n',\n",
       " '#c\\n',\n",
       " '#index0\\n',\n",
       " '\\n',\n",
       " '#*A+ Certification Core Hardware (Text & Lab Manual)\\n',\n",
       " '#@Charles J. Brooks\\n',\n",
       " '#t2003\\n',\n",
       " '#c\\n',\n",
       " '#index1\\n',\n",
       " '\\n',\n",
       " '#*Performance engineering in industry: current practices and adoption challenges\\n',\n",
       " '#@Ahmed E. Hassan,Parminder Flora\\n',\n",
       " '#t2007\\n',\n",
       " '#cProceedings of the 6th international workshop on Software and performance\\n',\n",
       " '#index2\\n',\n",
       " '#!This panel session discusses performance engineering practices in industry. Presentations in the session will explore the use of lightweight techniques and approaches in order to permit the cost effective and rapid adoption of performance modeling research by large industrial software systems.\\n',\n",
       " '\\n',\n",
       " '#*Dude, You Can Do It! How to Build a Sweeet PC\\n',\n",
       " '#@Darrel Creacy,Carlito Vicencio\\n',\n",
       " '#t2005\\n',\n",
       " '#c\\n',\n",
       " '#index3\\n',\n",
       " \"#!Whether you're frustrated with current PC offerings (and their inflated prices) or are simply looking for a cool project to take on, building a computer from the ground up using off-the-shelf parts can offer significant advantages. In these pages, computer dudes Darrel Wayne Creacy and Carlito Vicencio outline those advantages and then show you how to build the computer of your dreams. The pair begins by explaining what components make up a PC and what you need to think about when selecting those components, before helping you determine your needs and suggesting various configurations to fit those uses. Breaking the process down into its simplest terms, the authors provide component lists for a number of different PC setups: for students, home users, multimedia/home-theater enthusiasts, high-end graphic/video/audio producers, and more. Using plain language and plenty of visual and instructional aids--photos, illustrations, diagrams, step-by-step directions, and more--the authors ensure that even someone (like you!) who knows nothing about technology can build the perfect PC! On a more personal note, the authors are donating a percentage of their income from this book to the Breast Cancer Research Foundationï¾\\x96to thank all the women in their lives who have supported them and battled the disease. For more information about BCRF, please visit http://www.bcrfcure.org/.\\n\",\n",
       " '\\n',\n",
       " '#*What Every Programmer Needs to Know about Security (Advances in Information Security)\\n',\n",
       " '#@Neil Daswani,Anita Kesavan\\n',\n",
       " '#t2006\\n',\n",
       " '#c\\n',\n",
       " '#index4\\n',\n",
       " '\\n',\n",
       " '#*Interpreting Kullback-Leibler divergence with the Neyman-Pearson lemma\\n',\n",
       " '#@Shinto Eguchi,John Copas\\n',\n",
       " '#t2006\\n',\n",
       " '#cJournal of Multivariate Analysis\\n',\n",
       " '#index5\\n',\n",
       " '#%436405\\n',\n",
       " '#!Kullback-Leibler divergence and the Neyman-Pearson lemma are two fundamental concepts in statistics. Both are about likelihood ratios: Kullback-Leibler divergence is the expected log-likelihood ratio, and the Neyman-Pearson lemma is about error rates of likelihood ratio tests. Exploring this connection gives another statistical interpretation of the Kullback-Leibler divergence in terms of the loss of power of the likelihood ratio test when the wrong distribution is used for one of the hypotheses. In this interpretation, the standard non-negativity property of the Kullback-Leibler divergence is essentially a restatement of the optimal property of likelihood ratios established by the Neyman-Pearson lemma. The asymmetry of Kullback-Leibler divergence is overviewed in information geometry.\\n',\n",
       " '\\n',\n",
       " '#*Digital Media: Transformations in Human Communication\\n',\n",
       " '#@Lee Humphreys,Paul Messaris\\n',\n",
       " '#t2006\\n',\n",
       " '#c\\n',\n",
       " '#index6\\n',\n",
       " '\\n',\n",
       " '#*TOPP---the OpenMS proteomics pipeline\\n',\n",
       " '#@Oliver Kohlbacher,Knut Reinert,Clemens Gröpl,Eva Lange,Nico Pfeifer,Ole Schulz-Trieglaff,Marc Sturm\\n',\n",
       " '#t2007\\n',\n",
       " '#cBioinformatics\\n',\n",
       " '#index7\\n',\n",
       " \"#!Motivation: Experimental techniques in proteomics have seen rapid development over the last few years. Volume and complexity of the data have both been growing at a similar rate. Accordingly, data management and analysis are one of the major challenges in proteomics. Flexible algorithms are required to handle changing experimental setups and to assist in developing and validating new methods. In order to facilitate these studies, it would be desirable to have a flexible 'toolbox' of versatile and user-friendly applications allowing for rapid construction of computational workflows in proteomics. Results: We describe a set of tools for proteomics data analysis---TOPP, The OpenMS Proteomics Pipeline. TOPP provides a set of computational tools which can be easily combined into analysis pipelines even by non-experts and can be used in proteomics workflows. These applications range from useful utilities (file format conversion, peak picking) over wrapper applications for known applications (e.g. Mascot) to completely new algorithmic techniques for data reduction and data analysis. We anticipate that TOPP will greatly facilitate rapid prototyping of proteomics data evaluation pipelines. As such, we describe the basic concepts and the current abilities of TOPP and illustrate these concepts in the context of two example applications: the identification of peptides from a raw dataset through database search and the complex analysis of a standard addition experiment for the absolute quantitation of biomarkers. The latter example demonstrates TOPP's ability to construct flexible analysis pipelines in support of complex experimental setups. Availability: The TOPP components are available as open-source software under the lesser GNU public license (LGPL). Source code is available from the project website at www.OpenMS.de Contact: oliver.kohlbacher@uni-tuebingen.de\\n\",\n",
       " '\\n',\n",
       " '#*Type Graphics and MacIntosh\\n',\n",
       " '#@John Blaint\\n',\n",
       " '#t1987\\n',\n",
       " '#c\\n',\n",
       " '#index8\\n',\n",
       " '\\n',\n",
       " '#*Adaptive Hypermedia and Adaptive Web-Based Systems: 4th International Conference, AH 2006, Dublin, Ireland, June 21-23, 2006, Proceedings (Lecture Notes in Computer Science)\\n',\n",
       " '#@Vincent Wade,Helen Ashman,Barry Smyth\\n',\n",
       " '#t2006\\n',\n",
       " '#c\\n',\n",
       " '#index9\\n',\n",
       " '\\n',\n",
       " '#*Dependable Computing: Second Latin-American Symposium, LADC 2005, Salvador, Brazil, October 25-28, 2005, Proceedings (Lecture Notes in Computer Science)\\n',\n",
       " '#@Carlos Alberto Maziero,João Gabriel Silva,Aline Maria Santos Andrade,Flávio Morais de Assis Silva\\n',\n",
       " '#t2005\\n',\n",
       " '#c\\n',\n",
       " '#index10\\n',\n",
       " '\\n',\n",
       " '#*Calculus Early Transcendentals Single Variable\\n',\n",
       " '#@Howard A. Anton\\n',\n",
       " '#t2006\\n',\n",
       " '#c\\n',\n",
       " '#index11\\n',\n",
       " '\\n',\n",
       " '#*Webbots, Spiders, and Screen Scrapers\\n',\n",
       " '#@Michael Schrenk,Michael Shrenk\\n',\n",
       " '#t2007\\n',\n",
       " '#c\\n',\n",
       " '#index12\\n',\n",
       " \"#!The Internet is bigger and better than what a mere browser allows. Webbots, Spiders, and Screen Scrapers is for programmers and businesspeople who want to take full advantage of the vast resources available on the Web. There's no reason to let browsers limit your online experience-especially when you can easily automate online tasks to suit your individual needs. Learn how to write webbots and spiders that do all this and more: Programmatically download entire websites Effectively parse data from web pages Manage cookies Decode encrypted files Automate form submissions Send and receive email Send SMS alerts to your cell phone Unlock password-protected websites Automatically bid in online auctions Exchange data with FTP and NNTP servers Sample projects using standard code libraries reinforce these new skills. You'll learn how to create your own webbots and spiders that track online prices, aggregate different data sources into a single web page, and archive the online data you just can't live without. You'll learn inside information from an experienced webbot developer on how and when to write stealthy webbots that mimic human behavior, tips for developing fault-tolerant designs, and various methods for launching and scheduling webbots. You'll also get advice on how to write webbots and spiders that respect website owner property rights, plus techniques for shielding websites from unwanted robots. As a bonus, visit the author's website to test your webbots on sample target pages, and to download the scripts and code libraries used in the book. Some tasks are just too tedious-or too important!- to leave to humans. Once you've automated your online life, you'll never let a browser limit the way you use the Internet again.\\n\",\n",
       " '\\n',\n",
       " '#*Fast k-NN Classification Rule Using Metrics on Space-Filling Curves\\n',\n",
       " '#@E. Skubalska-Rafajtowicz,A. Krzyzak\\n',\n",
       " '#t1996\\n',\n",
       " '#cProceedings of the 13th International Conference on Pattern Recognition - Volume 2\\n',\n",
       " '#index13\\n',\n",
       " '\\n',\n",
       " '#*Making the Digital City: The Early Shaping of Urban Internet Space (Design & the Built Environment S.)\\n',\n",
       " '#@Alessandro Aurigi\\n',\n",
       " '#t2005\\n',\n",
       " '#c\\n',\n",
       " '#index14\\n',\n",
       " '\\n',\n",
       " '#*Linspire 5.0: The No Nonsense Guide! (No Nonsense Guide! series)\\n',\n",
       " '#@Eric Grebler\\n',\n",
       " '#t2005\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"outputacm.txt\")\n",
    " \n",
    "test = open(r\"outputacm.txt\", 'r',  encoding=\"utf8\") \n",
    "test.readlines()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(reference):\n",
    "    G.add_node(reference['index']) # add node\n",
    "    G.add_node(reference['index'], title=reference['title']) # add title attribute to node\n",
    "    G.add_node(reference['index'], journal=reference['journal']) # add journal attribute to node\n",
    "    for citation in reference['citations']:\n",
    "        G.add_edge(reference['index'], citation) # add edge to node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data():\n",
    "    with open(r'outputacm.txt', 'r',  encoding=\"utf8\") as f:\n",
    "        reference={}\n",
    "        citations=[]\n",
    "        readFile = f.readlines()\n",
    "        for line in readFile:\n",
    "            \n",
    "            if '#*' in line: # article title\n",
    "                if (bool(reference)):\n",
    "                    reference['citations'] = citations\n",
    "                    citations=[]\n",
    "                    create_graph(reference)\n",
    "                    try:\n",
    "                        yield reference\n",
    "                    except IndexError as e:\n",
    "                        continue\n",
    "                    reference={}\n",
    "                reference['title'] = line[2:].rstrip()\n",
    "            elif '#@' in line: # authors\n",
    "                reference['author'] = line[2:].rstrip().rsplit(\";\")\n",
    "            elif '#t' in line: # year published\n",
    "                reference['year'] = line[2:].rstrip()\n",
    "            elif '#c' in line: # journal\n",
    "                reference['journal'] = line[2:].rstrip()\n",
    "            elif '#index' in line: # index\n",
    "                reference['index'] = line[6:].rstrip()\n",
    "            elif '#%' in line: # id of cited paper\n",
    "                citations.append(line[2:].rstrip())\n",
    "            elif '#!' in line: # abstract\n",
    "                reference['abstract'] = line[2:].rstrip()\n",
    "        return reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(parse_data(), columns =('index', 'title', 'author',\n",
    "                                            'year', 'journal', 'citations', 'abstract'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629813 nodes\n",
      "632751 edges\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_nodes(), 'nodes')\n",
    "print(G.size(), 'edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Automated Deduction in Geometry: 5th Internati...</td>\n",
       "      <td>[Hoon Hong,Dongming Wang]</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A+ Certification Core Hardware (Text &amp; Lab Man...</td>\n",
       "      <td>[Charles J. Brooks]</td>\n",
       "      <td>2003</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Performance engineering in industry: current p...</td>\n",
       "      <td>[Ahmed E. Hassan,Parminder Flora]</td>\n",
       "      <td>2007</td>\n",
       "      <td>Proceedings of the 6th international workshop ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>This panel session discusses performance engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Dude, You Can Do It! How to Build a Sweeet PC</td>\n",
       "      <td>[Darrel Creacy,Carlito Vicencio]</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>Whether you're frustrated with current PC offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>What Every Programmer Needs to Know about Secu...</td>\n",
       "      <td>[Neil Daswani,Anita Kesavan]</td>\n",
       "      <td>2006</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                              title  \\\n",
       "0     0  Automated Deduction in Geometry: 5th Internati...   \n",
       "1     1  A+ Certification Core Hardware (Text & Lab Man...   \n",
       "2     2  Performance engineering in industry: current p...   \n",
       "3     3      Dude, You Can Do It! How to Build a Sweeet PC   \n",
       "4     4  What Every Programmer Needs to Know about Secu...   \n",
       "\n",
       "                              author  year  \\\n",
       "0          [Hoon Hong,Dongming Wang]  2006   \n",
       "1                [Charles J. Brooks]  2003   \n",
       "2  [Ahmed E. Hassan,Parminder Flora]  2007   \n",
       "3   [Darrel Creacy,Carlito Vicencio]  2005   \n",
       "4       [Neil Daswani,Anita Kesavan]  2006   \n",
       "\n",
       "                                             journal citations  \\\n",
       "0                                                           []   \n",
       "1                                                           []   \n",
       "2  Proceedings of the 6th international workshop ...        []   \n",
       "3                                                           []   \n",
       "4                                                           []   \n",
       "\n",
       "                                            abstract  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  This panel session discusses performance engin...  \n",
       "3  Whether you're frustrated with current PC offe...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_top = data.head() \n",
    "data_top  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629813, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Performance engineering in industry: current p...</td>\n",
       "      <td>[Ahmed E. Hassan,Parminder Flora]</td>\n",
       "      <td>2007</td>\n",
       "      <td>Proceedings of the 6th international workshop ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>This panel session discusses performance engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Dude, You Can Do It! How to Build a Sweeet PC</td>\n",
       "      <td>[Darrel Creacy,Carlito Vicencio]</td>\n",
       "      <td>2005</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>Whether you're frustrated with current PC offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Interpreting Kullback-Leibler divergence with ...</td>\n",
       "      <td>[Shinto Eguchi,John Copas]</td>\n",
       "      <td>2006</td>\n",
       "      <td>Journal of Multivariate Analysis</td>\n",
       "      <td>[436405]</td>\n",
       "      <td>Kullback-Leibler divergence and the Neyman-Pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>TOPP---the OpenMS proteomics pipeline</td>\n",
       "      <td>[Oliver Kohlbacher,Knut Reinert,Clemens Gröpl,...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Bioinformatics</td>\n",
       "      <td>[]</td>\n",
       "      <td>Motivation: Experimental techniques in proteom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Webbots, Spiders, and Screen Scrapers</td>\n",
       "      <td>[Michael Schrenk,Michael Shrenk]</td>\n",
       "      <td>2007</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>The Internet is bigger and better than what a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629804</td>\n",
       "      <td>629804</td>\n",
       "      <td>SENTINEL: a semantic business process monitori...</td>\n",
       "      <td>[Carlos Pedrinaci,Dave Lambert,Branimir Wetzst...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the first international worksho...</td>\n",
       "      <td>[12156, 29272, 29779, 88763, 261856, 340817, 4...</td>\n",
       "      <td>Business Activity Monitoring (BAM) aims to sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629806</td>\n",
       "      <td>629806</td>\n",
       "      <td>Effectiveness and usability of an online help ...</td>\n",
       "      <td>[Jérôme Simonin,Noëlle Carbonell,Danielle Pelé]</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the 10th international conferen...</td>\n",
       "      <td>[8543, 327540, 395578, 397153, 398612]</td>\n",
       "      <td>An empirical study is presented which aims at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629807</td>\n",
       "      <td>629807</td>\n",
       "      <td>Busy period analysis of finite QBD processes</td>\n",
       "      <td>[Chaitanya Garikiparthi,Appie van de Liefvoort...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ACM SIGMETRICS Performance Evaluation Review</td>\n",
       "      <td>[340965]</td>\n",
       "      <td>We present the number of customers served and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629808</td>\n",
       "      <td>629808</td>\n",
       "      <td>The Grid as a Single Entity: Towards a Behavio...</td>\n",
       "      <td>[Jesús Montes,Alberto Sánchez,Julio J. Valdés,...</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the OTM 2008 Confederated Inter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grids emerged in the last decade as large dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629811</td>\n",
       "      <td>629811</td>\n",
       "      <td>Multimodal system evaluation using modality ef...</td>\n",
       "      <td>[Manolis Perakakis,Alexandros Potamianos]</td>\n",
       "      <td>2008</td>\n",
       "      <td>Proceedings of the 10th international conferen...</td>\n",
       "      <td>[294663, 302639, 572828]</td>\n",
       "      <td>In this paper, we propose two new objective me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281078 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                              title  \\\n",
       "2            2  Performance engineering in industry: current p...   \n",
       "3            3      Dude, You Can Do It! How to Build a Sweeet PC   \n",
       "5            5  Interpreting Kullback-Leibler divergence with ...   \n",
       "7            7              TOPP---the OpenMS proteomics pipeline   \n",
       "12          12              Webbots, Spiders, and Screen Scrapers   \n",
       "...        ...                                                ...   \n",
       "629804  629804  SENTINEL: a semantic business process monitori...   \n",
       "629806  629806  Effectiveness and usability of an online help ...   \n",
       "629807  629807       Busy period analysis of finite QBD processes   \n",
       "629808  629808  The Grid as a Single Entity: Towards a Behavio...   \n",
       "629811  629811  Multimodal system evaluation using modality ef...   \n",
       "\n",
       "                                                   author  year  \\\n",
       "2                       [Ahmed E. Hassan,Parminder Flora]  2007   \n",
       "3                        [Darrel Creacy,Carlito Vicencio]  2005   \n",
       "5                              [Shinto Eguchi,John Copas]  2006   \n",
       "7       [Oliver Kohlbacher,Knut Reinert,Clemens Gröpl,...  2007   \n",
       "12                       [Michael Schrenk,Michael Shrenk]  2007   \n",
       "...                                                   ...   ...   \n",
       "629804  [Carlos Pedrinaci,Dave Lambert,Branimir Wetzst...  2008   \n",
       "629806    [Jérôme Simonin,Noëlle Carbonell,Danielle Pelé]  2008   \n",
       "629807  [Chaitanya Garikiparthi,Appie van de Liefvoort...  2008   \n",
       "629808  [Jesús Montes,Alberto Sánchez,Julio J. Valdés,...  2008   \n",
       "629811          [Manolis Perakakis,Alexandros Potamianos]  2008   \n",
       "\n",
       "                                                  journal  \\\n",
       "2       Proceedings of the 6th international workshop ...   \n",
       "3                                                           \n",
       "5                        Journal of Multivariate Analysis   \n",
       "7                                          Bioinformatics   \n",
       "12                                                          \n",
       "...                                                   ...   \n",
       "629804  Proceedings of the first international worksho...   \n",
       "629806  Proceedings of the 10th international conferen...   \n",
       "629807       ACM SIGMETRICS Performance Evaluation Review   \n",
       "629808  Proceedings of the OTM 2008 Confederated Inter...   \n",
       "629811  Proceedings of the 10th international conferen...   \n",
       "\n",
       "                                                citations  \\\n",
       "2                                                      []   \n",
       "3                                                      []   \n",
       "5                                                [436405]   \n",
       "7                                                      []   \n",
       "12                                                     []   \n",
       "...                                                   ...   \n",
       "629804  [12156, 29272, 29779, 88763, 261856, 340817, 4...   \n",
       "629806             [8543, 327540, 395578, 397153, 398612]   \n",
       "629807                                           [340965]   \n",
       "629808                                                 []   \n",
       "629811                           [294663, 302639, 572828]   \n",
       "\n",
       "                                                 abstract  \n",
       "2       This panel session discusses performance engin...  \n",
       "3       Whether you're frustrated with current PC offe...  \n",
       "5       Kullback-Leibler divergence and the Neyman-Pea...  \n",
       "7       Motivation: Experimental techniques in proteom...  \n",
       "12      The Internet is bigger and better than what a ...  \n",
       "...                                                   ...  \n",
       "629804  Business Activity Monitoring (BAM) aims to sup...  \n",
       "629806  An empirical study is presented which aims at ...  \n",
       "629807  We present the number of customers served and ...  \n",
       "629808  Grids emerged in the last decade as large dist...  \n",
       "629811  In this paper, we propose two new objective me...  \n",
       "\n",
       "[281078 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217335\n"
     ]
    }
   ],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c15887aadd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcommunities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentrality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgirvan_newman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36mgirvan_newman\u001b[0;34m(G, most_valuable_edge)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfloop_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0m_without_most_central_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_valuable_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36m_without_most_central_edges\u001b[0;34m(G, most_valuable_edge)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mnum_new_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_num_components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnum_new_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0moriginal_num_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0medge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmost_valuable_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mnew_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/algorithms/community/centrality.py\u001b[0m in \u001b[0;36mmost_valuable_edge\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# We have guaranteed that the graph is non-empty, so this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# dictionary will never be empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mbetweenness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_betweenness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetweenness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbetweenness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# The copy of G here must include the edge weight data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/jussiste/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-261>\u001b[0m in \u001b[0;36medge_betweenness_centrality\u001b[0;34m(G, k, normalized, weight, seed)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_random_state\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mnew_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_state_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36medge_betweenness_centrality\u001b[0;34m(G, k, normalized, weight, seed)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# single source shortest paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use BFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_shortest_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use Dijkstra's algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_dijkstra_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36m_single_source_shortest_path_basic\u001b[0;34m(G, s)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0msigmav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 2500\n",
    "\n",
    "communities=nx.algorithms.community.centrality.girvan_newman(G)\n",
    "\n",
    "tuple(sorted(c) for c in next(communities))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.takewhile object at 0x7f3a3c63f690>\n"
     ]
    }
   ],
   "source": [
    "print(limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distance(G, start, end, distance):\n",
    "    edges=list(nx.bfs_edges(G, start, depth_limit=distance))\n",
    "    nodes = [start] + [v for u, v in edges]\n",
    "    return end in nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x= nx.path_graph(10)\n",
    "\n",
    "print(x)\n",
    "print(check_distance(x, 0, 5, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
